{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPHUVL77R3qH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fe51781-04e4-489e-cb36-2baf2661ec87"
      },
      "source": [
        "# To upload our datasets from our working directory we need to mount our drive contents to the colab environment. \n",
        "# For the code to do so you can search “mount” in code snippets or use the code given below. \n",
        "# Our entire drive contents are now mounted on colab at the location “/gdrive”.\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "#Change current working directory to gdrive\n",
        "%cd /gdrive\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLG4iks102sl",
        "outputId": "9e74a08b-25b8-4a34-cd7b-acfe01b9d7b1"
      },
      "source": [
        "!pip install vecstack\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting vecstack\n",
            "  Downloading vecstack-0.4.0.tar.gz (18 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.7.3)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from vecstack) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->vecstack) (1.2.0)\n",
            "Building wheels for collected packages: vecstack\n",
            "  Building wheel for vecstack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vecstack: filename=vecstack-0.4.0-py3-none-any.whl size=19877 sha256=4e18ac2b6edc0bee68b37828573fbfd982de0523ae3835c9c8b2c388438dd72a\n",
            "  Stored in directory: /root/.cache/pip/wheels/28/fe/0c/fe8e43660e3316d7ce204e59a79a72246c0ae9b6c5c79841c8\n",
            "Successfully built vecstack\n",
            "Installing collected packages: vecstack\n",
            "Successfully installed vecstack-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "md5Ek9GT13Yb"
      },
      "source": [
        "from vecstack import stacking\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score #works\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "#from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE \n",
        "from sklearn.svm import SVC\n",
        "from collections import Counter #for Smote, \n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bQ9eJR819Cp",
        "outputId": "7c422bd5-06f5-48ba-d1cc-e6594501e474"
      },
      "source": [
        "\n",
        "trainfile = r'/gdrive/My Drive/508IndividualAssignment3/RevisedHomesiteTrain1.csv'\n",
        "train_data = pd.read_csv(trainfile)\n",
        "\n",
        "#train_data = pd.read_csv(\"C:/Users/admin/Downloads/Insurance Fraud - TRAIN-3000(1).csv\")\n",
        "\n",
        "\n",
        "testfile = r'/gdrive/My Drive/508IndividualAssignment3/RevisedHomesiteTest1.csv'\n",
        "test_data = pd.read_csv(testfile)\n",
        "\n",
        "#test_data = pd.read_csv(\"C:/Users/admin/Downloads/Insurance Fraud -TEST-12900(1).csv\")\n",
        "\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_data.head())    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(65000, 596)\n",
            "(173836, 596)\n",
            "   CoverageField11A  CoverageField11B  CoverageField1A  CoverageField1B  \\\n",
            "0                 2                 1               17               23   \n",
            "1                 5                 9                6                8   \n",
            "2                 4                 6                7               12   \n",
            "3                15                23                3                2   \n",
            "4                 4                 6                8               13   \n",
            "\n",
            "   CoverageField2A  CoverageField2B  CoverageField3A  CoverageField3B  \\\n",
            "0               17               23               15               22   \n",
            "1                6                8                5                7   \n",
            "2                7               12                6               10   \n",
            "3                3                2                2                2   \n",
            "4                8               13                7               11   \n",
            "\n",
            "   CoverageField4A  CoverageField4B  ...  PropertyField38_N  \\\n",
            "0               16               22  ...                  1   \n",
            "1                5                8  ...                  1   \n",
            "2                7               11  ...                  1   \n",
            "3                3                2  ...                  1   \n",
            "4                7               13  ...                  1   \n",
            "\n",
            "   PropertyField38_Y  GeographicField63_   GeographicField63_N  \\\n",
            "0                  0                    0                    1   \n",
            "1                  0                    0                    1   \n",
            "2                  0                    0                    1   \n",
            "3                  0                    0                    1   \n",
            "4                  0                    0                    1   \n",
            "\n",
            "   GeographicField63_Y  GeographicField64_CA  GeographicField64_IL  \\\n",
            "0                    0                     1                     0   \n",
            "1                    0                     0                     0   \n",
            "2                    0                     0                     0   \n",
            "3                    0                     0                     0   \n",
            "4                    0                     0                     1   \n",
            "\n",
            "   GeographicField64_NJ  GeographicField64_TX  QuoteConversion_Flag  \n",
            "0                     0                     0                     0  \n",
            "1                     1                     0                     0  \n",
            "2                     1                     0                     0  \n",
            "3                     0                     1                     0  \n",
            "4                     0                     0                     0  \n",
            "\n",
            "[5 rows x 596 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZArBnwvC2a9V",
        "outputId": "63450a48-421b-46e4-b07a-da1a8cc6ed8a"
      },
      "source": [
        "# Seperate Target column from Train Data\n",
        "TrainCols = list(train_data.columns.values)\n",
        "TestCols = list(test_data.columns.values)\n",
        "\n",
        "X_train1 = train_data[TrainCols[0:len(TrainCols)-1]].copy()\n",
        "y_train = train_data[['QuoteConversion_Flag']].copy()\n",
        "print(\"Train Set shape:\")\n",
        "print(X_train1.shape)\n",
        "print(y_train.shape)\n",
        "X_test1 = test_data[TestCols[0:len(TestCols)-1]].copy()\n",
        "#y_test1 = test_data[['FRAUDFOUND']].copy()\n",
        "print(\"Test Set shape:\")\n",
        "print(X_test1.shape)\n",
        "#print(y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set shape:\n",
            "(65000, 595)\n",
            "(65000, 1)\n",
            "Test Set shape:\n",
            "(173836, 595)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V234VI_b9yIR"
      },
      "source": [
        "#CONSTRUCT DEFAULT DECISION TREE AND OBTAIN RESPECTIVE ACCURACY \n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train1,y_train)\n",
        "clf_predict=clf.predict(X_test1)\n",
        "print(\"accuracy Score (training) for Decision Tree:{0:6f}\".format(clf.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix for Decision Tree\")\n",
        "print(confusion_matrix(y_test,clf_predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxXQAWLD2pqy"
      },
      "source": [
        "#Hyperparameter tuning done for decision tree classifier\n",
        "parameters={'min_samples_split' : range(10,100,10),'max_depth': range(1,20,2)}\n",
        "clf_random = RandomizedSearchCV(clf,parameters,n_iter=15)\n",
        "clf_random.fit(X_train1, y_train)\n",
        "grid_parm=clf_random.best_params_\n",
        "print(grid_parm)\n",
        "\n",
        "#Using the parameters obtained from HyperParameterTuning in the DecisionTreeClassifier \n",
        "clf = DecisionTreeClassifier(**grid_parm)\n",
        "clf.fit(X_train1,y_train)\n",
        "clf_predict = clf.predict(X_test1)\n",
        "\n",
        "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
        "print(\"accuracy Score (training) after hypertuning for Decision Tree:{0:6f}\".format(clf.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix after hypertuning for Decision Tree\")\n",
        "print(confusion_matrix(y_test,clf_predict))\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test,clf_predict))\n",
        "\n",
        "#get cross-validation report\n",
        "clf_cv_score = cross_val_score(clf, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(clf_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Decision Tree: \",clf_cv_score.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzDIdb4W_Aj8"
      },
      "source": [
        "#Construct Random Forest Model\n",
        "\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train1, y_train)\n",
        "rfc_predict=rfc.predict(X_test1)\n",
        "print(\"accuracy Score (training) for RandomForest:{0:6f}\".format(rfc.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix for Random Forest:\")\n",
        "print(confusion_matrix(y_test,rfc_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOt6_R43CF9"
      },
      "source": [
        "#Hyperparameter tuning for random forest classifier\n",
        "rfc_random = RandomizedSearchCV(rfc,parameters,n_iter=15)\n",
        "rfc_random.fit(X_train1, y_train)\n",
        "grid_parm_rfc=rfc_random.best_params_\n",
        "print(grid_parm_rfc)\n",
        "\n",
        "#Construct Random Forest with best parameters\n",
        "rfc= RandomForestClassifier(**grid_parm_rfc)\n",
        "rfc.fit(X_train1,y_train)\n",
        "rfc_predict = rfc.predict(X_test1)\n",
        "print(\"accuracy Score (training) after hypertuning for Random Forest:{0:6f}\".format(rfc.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix after hypertuning for Random Forest:\")\n",
        "print(confusion_matrix(y_test,rfc_predict))\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test,rfc_predict))\n",
        "\n",
        "#get cross-validation report\n",
        "rfc_cv_score = cross_val_score(rfc, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(rfc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Random Forest: \",rfc_cv_score.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm2iiPC8S5ij"
      },
      "source": [
        "#Construct MultiLayer Perceptron Model\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "mlp = MLPClassifier(max_iter=100)\n",
        "mlp.fit(X_train1, y_train)\n",
        "mlp_predict=mlp.predict(X_test1)\n",
        "print(\"accuracy Score (training) for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix for MultiLayer Perceptron:\")\n",
        "print(confusion_matrix(y_test,mlp_predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxwFiz_aUunO"
      },
      "source": [
        "#Hyperparameter tuning done for MultiLayer Perceptron classifier\n",
        "\n",
        "#parameters = {'hidden_layer_sizes':[(10,), (20,)], 'activation':['tanh', 'relu'], 'solver':['sgd', 'adam'], 'alpha': [0.0001, 0.05], 'learning_rate':['constant', 'adaptive']}\n",
        "#parameters = {'hidden_layer_sizes':[(10,5), (20,5)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive']}\n",
        "parameters = {'hidden_layer_sizes':[(10,5,3), (20,7,3)], 'activation':['tanh', 'relu'], 'learning_rate':['constant', 'adaptive'], 'max_iter' :[100, 150]}\n",
        "#parameters = {'hidden_layer_sizes':[(10,), (15,), (10,5), (20,7,3)]}\n",
        "\n",
        "mlp_random = RandomizedSearchCV(mlp,parameters,n_iter=15)\n",
        "mlp_random.fit(X_train1, y_train)\n",
        "grid_parm=mlp_random.best_params_\n",
        "print(grid_parm)\n",
        "\n",
        "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
        "mlp = MLPClassifier(**grid_parm)\n",
        "mlp.fit(X_train1,y_train)\n",
        "mlp_predict = mlp.predict(X_test1)\n",
        "\n",
        "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
        "print(\"accuracy Score (training) after hypertuning for MultiLayer Perceptron:{0:6f}\".format(mlp.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix after hypertuning for MultiLayer Perceptron\")\n",
        "print(confusion_matrix(y_test,mlp_predict))\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test,mlp_predict))\n",
        "\n",
        "#get cross-validation report\n",
        "mlp_cv_score = cross_val_score(mlp, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(mlp_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - MultiLayer Perceptron: \",mlp_cv_score.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FqqjbunCWC_"
      },
      "source": [
        "#Construct K-Nearest Neighbor Model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "neigh.fit(X_train1, y_train)\n",
        "neigh_predict=neigh.predict(X_test1)\n",
        "print(\"accuracy Score (training) for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix for KNeighborsClassifier:\")\n",
        "print(confusion_matrix(y_test,neigh_predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrpvdAdwETC0"
      },
      "source": [
        "#Hyperparameter tuning done for K-Nearest Neighbor classifier\n",
        "\n",
        "parameters = {'n_neighbors':[3,5,7,9,11], 'weights':['uniform', 'distance'], 'p':[1,2]}\n",
        "\n",
        "\n",
        "neigh_random = RandomizedSearchCV(neigh,parameters,n_iter=15)\n",
        "neigh_random.fit(X_train1, y_train)\n",
        "grid_parm=neigh_random.best_params_\n",
        "print(grid_parm)\n",
        "\n",
        "#Using the parameters obtained from HyperParameterTuning in the MLPClassifier \n",
        "neigh = KNeighborsClassifier(**grid_parm)\n",
        "neigh.fit(X_train1,y_train)\n",
        "neigh_predict = neigh.predict(X_test1)\n",
        "\n",
        "#Obtain accuracy ,confusion matrix,classification report and AUC values for the result above.\n",
        "print(\"accuracy Score (training) after hypertuning for KNeighborsClassifier:{0:6f}\".format(neigh.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix after hypertuning for KNeighborsClassifier\")\n",
        "print(confusion_matrix(y_test,neigh_predict))\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test,neigh_predict))\n",
        "\n",
        "#get cross-validation report\n",
        "neigh_cv_score = cross_val_score(neigh, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(neigh_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - KNeighborsClassifier: \",neigh_cv_score.mean())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKIldb73eMRl"
      },
      "source": [
        "#Construct Linear Support Vector Machine Model\n",
        "from sklearn.svm import LinearSVC \n",
        "linsvm = LinearSVC(max_iter=300) \n",
        "linsvm.fit(X_train1, y_train) \n",
        "linsvm_predict=linsvm.predict(X_test1) \n",
        "print(\"accuracy Score (training) for Linear SVM Classifier:{0:6f}\".format(linsvm.score(X_test1,y_test))) \n",
        "print(\"Confusion Matrix for Linear SVM Classifier:\") \n",
        "print(confusion_matrix(y_test,linsvm_predict))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvCQJN2CiKY0"
      },
      "source": [
        "#Construct Support Vector Machine Model\n",
        "from sklearn.svm import SVC \n",
        "svm = SVC(max_iter=500) \n",
        "svm.fit(X_train1, y_train) \n",
        "svm_predict=svm.predict(X_test1) \n",
        "print(\"accuracy Score (training) for SVM Classifier:{0:6f}\".format(svm.score(X_test1,y_test))) \n",
        "print(\"Confusion Matrix for SVM Classifier:\") \n",
        "print(confusion_matrix(y_test,svm_predict))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuhgy0RcseYE"
      },
      "source": [
        "#Construct Gradient Boosting model\n",
        "\n",
        "search_grid={'n_estimators':[5,10,20],'learning_rate':[0.01,.1]}\n",
        "abc =GradientBoostingClassifier()\n",
        "abc.fit(X_train1, y_train)\n",
        "abc_predict=abc.predict(X_test1)\n",
        "print(\"accuracy Score (training) for Boosting:{0:6f}\".format(abc.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix for boosting:\")\n",
        "print(confusion_matrix(y_test,abc_predict))\n",
        "abc_random = RandomizedSearchCV(abc,search_grid,n_iter=15)\n",
        "abc_random.fit(X_train1, y_train)\n",
        "grid_parm_abc=abc_random.best_params_\n",
        "print(grid_parm_abc)\n",
        "abc= GradientBoostingClassifier(**grid_parm_abc)\n",
        "abc.fit(X_train1,y_train)\n",
        "abc_predict = abc.predict(X_test1)\n",
        "print(\"accuracy Score (training) after hypertuning for Boosting:{0:6f}\".format(abc.score(X_test1,y_test)))\n",
        "print(\"Confusion Matrix after hypertuning for Boosting:\")\n",
        "print(confusion_matrix(y_test,abc_predict))\n",
        "print(\"=== Classification Report ===\")\n",
        "print(classification_report(y_test,abc_predict))\n",
        "abc_cv_score = cross_val_score(abc, X_train1, y_train, cv=10, scoring=\"roc_auc\")\n",
        "print(\"=== All AUC Scores ===\")\n",
        "print(abc_cv_score)\n",
        "print('\\n')\n",
        "print(\"=== Mean AUC Score ===\")\n",
        "print(\"Mean AUC Score - Boosting: \",abc_cv_score.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdhKtuqXQ73r"
      },
      "source": [
        "# ***SMOTE***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwMoUt2eQ5re"
      },
      "source": [
        "print(\"___________________________________________________________________\\nSMOTE\\n\")\n",
        "print('Original dataset shape %s' % Counter(y_train))\n",
        "sm = SMOTE(sampling_strategy='float', ratio=0.5)\n",
        "X_res, y_res = sm.fit_resample(X_train1, y_train)\n",
        "print('Resampled dataset shape %s' % Counter(y_res))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XD8njUjRXJv"
      },
      "source": [
        "# ***ENSEMBLE METHODS STACKING***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS4c_BpQRQ0O"
      },
      "source": [
        "print(\"___________________________________________________________________________________________\\nEnsemble Methods Predictions using GradientBoosting, RandomForest and Decision Tree Classifier\\n\")\n",
        "\n",
        "models = [ KNeighborsClassifier(), MLPClassifier(), SVC(), LinearSVC(), RandomForestClassifier(), DecisionTreeClassifier() ]\n",
        "      \n",
        "S_Train, S_Test = stacking(models,                   \n",
        "                           X_res, y_res, X_test1,   \n",
        "                           regression=False, \n",
        "     \n",
        "                           mode='oof_pred_bag', \n",
        "       \n",
        "                           needs_proba=False,\n",
        "         \n",
        "                           save_dir=None, \n",
        "            \n",
        "                           metric=accuracy_score, \n",
        "    \n",
        "                           n_folds=4, \n",
        "                 \n",
        "                           stratified=True,\n",
        "            \n",
        "                           shuffle=True,  \n",
        "            \n",
        "                           random_state=0,    \n",
        "         \n",
        "                           verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_vyEanlkcKl"
      },
      "source": [
        "model = MLPClassifier()\n",
        "    \n",
        "model = model.fit(S_Train, y_res)\n",
        "y_pred = model.predict(S_Test)\n",
        "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVeE_7ZktRo"
      },
      "source": [
        "model = KNeighborsClassifier()\n",
        "    \n",
        "model = model.fit(S_Train, y_res)\n",
        "y_pred = model.predict(S_Test)\n",
        "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv-CE4ZLRjJS"
      },
      "source": [
        "model = GradientBoostingClassifier()\n",
        "    \n",
        "model = model.fit(S_Train, y_res)\n",
        "y_pred = model.predict(S_Test)\n",
        "print('Final prediction score for ensemble methods: [%.8f]' % accuracy_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wffof6dLRo6J"
      },
      "source": [
        "#Get Prediction Probability for the predicted class as a dataframe\n",
        "pred_Probability =pd.DataFrame(model.predict_proba(S_Test))\n",
        "\n",
        "pred_Probability.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}